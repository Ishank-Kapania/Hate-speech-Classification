{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install 'transformers[torch]'"
      ],
      "metadata": {
        "id": "00ls2WfrT3n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1v1Raj_5R2_s"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "set_seeds(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "1vL3nVdQdfCo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ltrctelugu/bert_ltrc_telugu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ltrctelugu/bert_ltrc_telugu\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "FoQpDE6hR6IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_args = TrainingArguments(\n",
        "        'outputs',\n",
        "        evaluation_strategy = \"epoch\",\n",
        "        save_strategy = \"epoch\",\n",
        "        learning_rate = 2e-5,\n",
        "        per_device_train_batch_size = 250,\n",
        "        per_device_eval_batch_size = 250,\n",
        "        num_train_epochs = 10,\n",
        "        weight_decay = 0.01,\n",
        "        load_best_model_at_end = True,\n",
        "        metric_for_best_model = 'f1_macro'\n",
        "    )"
      ],
      "metadata": {
        "id": "drpixoqrTnFB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LTRCDataset(Dataset):\n",
        "    def __init__(self, text, labels, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=False,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "o_FLa3pQTznb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/data/ltrc/ltrc_tel_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/ltrc/ltrc_tel_test.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/data/ltrc/ltrc_tel_val.csv')"
      ],
      "metadata": {
        "id": "LgH3O6VaUE2x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(df):\n",
        "  return LTRCDataset(text=df.text.to_numpy(), labels=df.label_yn.to_numpy(), tokenizer=tokenizer, max_len=128)"
      ],
      "metadata": {
        "id": "c23QTv3bcpjw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = prepare_dataset(train_df)\n",
        "test_ds = prepare_dataset(test_df)\n",
        "val_ds = prepare_dataset(val_df)"
      ],
      "metadata": {
        "id": "at5JyLCZdAxd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(preds, labels):\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1_micro = f1_score(labels, preds, average='micro')\n",
        "    f1_macro = f1_score(labels, preds, average='macro')\n",
        "    print ('jacc acc:{}, f1 micro score:{} f1 macro score:{}'.format(acc, f1_micro, f1_macro))\n",
        "    return acc, f1_micro, f1_macro\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc, f1_micro, f1_macro = get_metrics(preds, labels)\n",
        "    print(f\"accuracy: {acc}, f1_macro: {f1_macro}, f1_micro: {f1_micro}\")\n",
        "    #return {'accuracy': acc, \"f1_macro\": f1_macro, \"f1_micro\": f1_micro}\n",
        "    return {'f1_macro':f1_macro, 'accuracy':acc}"
      ],
      "metadata": {
        "id": "Q_QI_SlMdU-R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        args=train_args,\n",
        "        train_dataset = train_ds,\n",
        "        eval_dataset = val_ds,\n",
        "        tokenizer = tokenizer,\n",
        "        compute_metrics = compute_metrics\n",
        "    )"
      ],
      "metadata": {
        "id": "xr8KqytNdDDm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "tnp9-qc3dZlh",
        "outputId": "057cd1a8-c6b6-43e0-a003-91f4f38996c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [990/990 20:03, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.049789</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.050092</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.049875</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.049865</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.050079</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.050044</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.050256</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.050822</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.050035</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.050038</td>\n",
              "      <td>0.497782</td>\n",
              "      <td>0.991168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n",
            "jacc acc:0.9911680911680911, f1 micro score:0.9911680911680911 f1 macro score:0.4977822292173415\n",
            "accuracy: 0.9911680911680911, f1_macro: 0.4977822292173415, f1_micro: 0.9911680911680911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=990, training_loss=0.05878128475613064, metrics={'train_runtime': 1204.9024, 'train_samples_per_second': 204.158, 'train_steps_per_second': 0.822, 'total_flos': 1.61806721270016e+16, 'train_loss': 0.05878128475613064, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.predict(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "64CwLCaxdmlX",
        "outputId": "5fe0a79f-ad36-4965-c736-8ba0ced5080d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jacc acc:0.9891938006540595, f1 micro score:0.9891938006540595 f1 macro score:0.4972837741243746\n",
            "accuracy: 0.9891938006540595, f1_macro: 0.4972837741243746, f1_micro: 0.9891938006540595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bfbNujsltnr",
        "outputId": "13bef3a8-a370-4183-ce31-7341a31fc4c9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 2.2513857, -2.5532396],\n",
              "       [ 2.2688046, -2.5743685],\n",
              "       [ 2.2881477, -2.5997906],\n",
              "       ...,\n",
              "       [ 2.361202 , -2.6864018],\n",
              "       [ 2.3157024, -2.6394453],\n",
              "       [ 2.446384 , -2.8146782]], dtype=float32), label_ids=array([0, 0, 0, ..., 0, 0, 0]), metrics={'test_loss': 0.05927256494760513, 'test_f1_macro': 0.4972837741243746, 'test_accuracy': 0.9891938006540595, 'test_runtime': 11.9966, 'test_samples_per_second': 586.249, 'test_steps_per_second': 2.417})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxFXYL0Zlyw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}