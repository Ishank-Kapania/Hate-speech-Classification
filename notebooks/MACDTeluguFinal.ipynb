{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA6TVWGFtOpo"
      },
      "outputs": [],
      "source": [
        "!pip install 'transformers[torch]' torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TilFnZ4ZuONu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seeds(393)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_metrics(preds, labels):\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1_micro = f1_score(labels, preds, average='micro')\n",
        "    f1_macro = f1_score(labels, preds, average='macro')\n",
        "    print ('jacc acc:{}, f1 micro score:{} f1 macro score:{}'.format(acc, f1_micro, f1_macro))\n",
        "    return acc, f1_micro, f1_macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDbR0jAPvYQ4",
        "outputId": "1150927d-e979-4793-c949-2c0ec1503f48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/data/abusexlmr')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/data/abusexlmr', num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jTtwbfKWoe8K"
      },
      "outputs": [],
      "source": [
        "train_args = TrainingArguments(\n",
        "        'outputs',\n",
        "        evaluation_strategy = \"epoch\",\n",
        "        save_strategy = \"epoch\",\n",
        "        learning_rate = 2e-5,\n",
        "        per_device_train_batch_size = 10,\n",
        "        per_device_eval_batch_size = 10,\n",
        "        num_train_epochs = 10,\n",
        "        weight_decay = 0.01,\n",
        "        load_best_model_at_end = True,\n",
        "        metric_for_best_model = 'f1_macro'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tyCNqJ76p59Z"
      },
      "outputs": [],
      "source": [
        "class MACDataset(Dataset):\n",
        "    def __init__(self, text, labels, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=False,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x5562O0Jp9BK"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df):\n",
        "  return MACDataset(text=df.text.to_numpy(), labels=df.label_yn.to_numpy(), tokenizer=tokenizer, max_len=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RdAH7ltVqHD3"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/data/telugu/final_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/telugu/final_test.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/data/telugu/final_val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bwkobPIUqUYD"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare_dataset(train_df)\n",
        "test_ds = prepare_dataset(test_df)\n",
        "val_ds = prepare_dataset(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pwoOppbIqWh3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc, f1_micro, f1_macro = get_metrics(preds, labels)\n",
        "    print(f\"accuracy: {acc}, f1_macro: {f1_macro}, f1_micro: {f1_micro}\")\n",
        "    #return {'accuracy': acc, \"f1_macro\": f1_macro, \"f1_micro\": f1_micro}\n",
        "    return {'f1_macro':f1_macro, 'accuracy':acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KMroe8V0qYo2"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        args=train_args,\n",
        "        train_dataset = train_ds,\n",
        "        eval_dataset = val_ds,\n",
        "        tokenizer = tokenizer,\n",
        "        compute_metrics = compute_metrics\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "QmANwM1SqafY",
        "outputId": "7539b140-dd30-486d-c3d0-8632dc43a1d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42600' max='42600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [42600/42600 1:22:54, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.159900</td>\n",
              "      <td>0.243570</td>\n",
              "      <td>0.917834</td>\n",
              "      <td>0.931335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.125300</td>\n",
              "      <td>0.326668</td>\n",
              "      <td>0.923353</td>\n",
              "      <td>0.934805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.088100</td>\n",
              "      <td>0.336456</td>\n",
              "      <td>0.920009</td>\n",
              "      <td>0.932387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.062800</td>\n",
              "      <td>0.452032</td>\n",
              "      <td>0.917415</td>\n",
              "      <td>0.930810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.038600</td>\n",
              "      <td>0.531608</td>\n",
              "      <td>0.908322</td>\n",
              "      <td>0.922608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.516352</td>\n",
              "      <td>0.917709</td>\n",
              "      <td>0.930179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>0.552390</td>\n",
              "      <td>0.918371</td>\n",
              "      <td>0.930494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.529292</td>\n",
              "      <td>0.920994</td>\n",
              "      <td>0.932492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.638246</td>\n",
              "      <td>0.917990</td>\n",
              "      <td>0.930810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.666620</td>\n",
              "      <td>0.921229</td>\n",
              "      <td>0.933018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jacc acc:0.931335436382755, f1 micro score:0.931335436382755 f1 macro score:0.9178340036577584\n",
            "accuracy: 0.931335436382755, f1_macro: 0.9178340036577584, f1_micro: 0.931335436382755\n",
            "jacc acc:0.9348054679284963, f1 micro score:0.9348054679284963 f1 macro score:0.9233534325292078\n",
            "accuracy: 0.9348054679284963, f1_macro: 0.9233534325292078, f1_micro: 0.9348054679284963\n",
            "jacc acc:0.9323869610935857, f1 micro score:0.9323869610935857 f1 macro score:0.9200087843525817\n",
            "accuracy: 0.9323869610935857, f1_macro: 0.9200087843525817, f1_micro: 0.9323869610935857\n",
            "jacc acc:0.9308096740273396, f1 micro score:0.9308096740273396 f1 macro score:0.9174147961230652\n",
            "accuracy: 0.9308096740273396, f1_macro: 0.9174147961230652, f1_micro: 0.9308096740273396\n",
            "jacc acc:0.9226077812828601, f1 micro score:0.9226077812828601 f1 macro score:0.9083224427900691\n",
            "accuracy: 0.9226077812828601, f1_macro: 0.9083224427900691, f1_micro: 0.9226077812828601\n",
            "jacc acc:0.9301787592008413, f1 micro score:0.9301787592008413 f1 macro score:0.9177087946595006\n",
            "accuracy: 0.9301787592008413, f1_macro: 0.9177087946595006, f1_micro: 0.9301787592008413\n",
            "jacc acc:0.9304942166140905, f1 micro score:0.9304942166140905 f1 macro score:0.9183705562580451\n",
            "accuracy: 0.9304942166140905, f1_macro: 0.9183705562580451, f1_micro: 0.9304942166140905\n",
            "jacc acc:0.9324921135646688, f1 micro score:0.9324921135646688 f1 macro score:0.9209937829943111\n",
            "accuracy: 0.9324921135646688, f1_macro: 0.9209937829943111, f1_micro: 0.9324921135646688\n",
            "jacc acc:0.9308096740273396, f1 micro score:0.9308096740273396 f1 macro score:0.9179898430588775\n",
            "accuracy: 0.9308096740273396, f1_macro: 0.9179898430588775, f1_micro: 0.9308096740273396\n",
            "jacc acc:0.9330178759200841, f1 micro score:0.9330178759200842 f1 macro score:0.9212292392884063\n",
            "accuracy: 0.9330178759200841, f1_macro: 0.9212292392884063, f1_micro: 0.9330178759200842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=42600, training_loss=0.054471786239057636, metrics={'train_runtime': 4974.6299, 'train_samples_per_second': 85.633, 'train_steps_per_second': 8.563, 'total_flos': 2.80206696182016e+16, 'train_loss': 0.054471786239057636, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC3e18Gqqc3r",
        "outputId": "c2b11763-6f27-4abd-ba49-e716969069e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YuWe3-z-tmfH"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Nr1Wk_NtqGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "688b4c5a-812c-49eb-8f0a-53ed69c3b66a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jacc acc:0.9444487071280595, f1 micro score:0.9444487071280595 f1 macro score:0.9191846913018573\n",
            "accuracy: 0.9444487071280595, f1_macro: 0.9191846913018573, f1_micro: 0.9444487071280595\n"
          ]
        }
      ],
      "source": [
        "test_metrics = trainer.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puLG_YtHVG11",
        "outputId": "9a37ede9-c77e-476a-9c36-aac0769b225b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 3.7194731, -4.5912337],\n",
              "       [-3.3240883,  3.675735 ],\n",
              "       [-3.5344553,  3.9739187],\n",
              "       ...,\n",
              "       [ 2.9705765, -3.4781687],\n",
              "       [ 3.247798 , -3.9461331],\n",
              "       [ 3.2790737, -3.8932557]], dtype=float32), label_ids=array([0, 1, 1, ..., 0, 0, 0]), metrics={'test_loss': 0.27196773886680603, 'test_f1_macro': 0.9191846913018573, 'test_accuracy': 0.9444487071280595, 'test_runtime': 38.5401, 'test_samples_per_second': 338.167, 'test_steps_per_second': 33.835})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_test_df = pd.read_csv('/content/drive/MyDrive/data/telugu/macd_tel_test.csv')\n",
        "original_test_ds = prepare_dataset(original_test_df)"
      ],
      "metadata": {
        "id": "8cbiDeecVSkP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_test_metrics = trainer.predict(original_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nYiVXjY9Xv63",
        "outputId": "ccb73f51-f071-439f-dafb-6698bf924a9d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jacc acc:0.9045, f1 micro score:0.9045 f1 macro score:0.9040364721696976\n",
            "accuracy: 0.9045, f1_macro: 0.9040364721696976, f1_micro: 0.9045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJb3vvqBX6uE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}