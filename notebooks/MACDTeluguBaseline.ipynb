{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA6TVWGFtOpo"
      },
      "outputs": [],
      "source": [
        "!pip install 'transformers[torch]' torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seeds(393)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_metrics(preds, labels):\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1_micro = f1_score(labels, preds, average='micro')\n",
        "    f1_macro = f1_score(labels, preds, average='macro')\n",
        "    print ('jacc acc:{}, f1 micro score:{} f1 macro score:{}'.format(acc, f1_micro, f1_macro))\n",
        "    return acc, f1_micro, f1_macro"
      ],
      "metadata": {
        "id": "TilFnZ4ZuONu"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/data/abusexlmr')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/data/abusexlmr', num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDbR0jAPvYQ4",
        "outputId": "6d22bf77-8706-44c9-9900-7e2f9e06829c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = pd.read_csv('/content/drive/MyDrive/data/telugu/macd_tel_test.csv')\n",
        "accuracy = []\n",
        "f1_micro = []\n",
        "f1_macro = []\n",
        "for i in range(0, 5000, 1000):\n",
        "  test_text, test_labels = list(test_dataset.text)[i:i+1000], list(test_dataset.label_yn)[i:i+1000]\n",
        "  test_encodings = tokenizer(test_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "  test_encodings = test_encodings.to(device)\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**test_encodings)\n",
        "  predicted_labels = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "  print(f'Batch {(i + 1000) // 1000}')\n",
        "  a, f1m, f1M = get_metrics(predicted_labels, test_labels)\n",
        "  accuracy.append(a)\n",
        "  f1_micro.append(f1m)\n",
        "  f1_macro.append(f1M)"
      ],
      "metadata": {
        "id": "_GKYyOqMv5PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65571649-ddb9-4583-b17c-ed7c9704291b"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1\n",
            "jacc acc:0.939, f1 micro score:0.939 f1 macro score:0.9389950585997466\n",
            "Batch 2\n",
            "jacc acc:0.92, f1 micro score:0.92 f1 macro score:0.9196283615437785\n",
            "Batch 3\n",
            "jacc acc:0.924, f1 micro score:0.924 f1 macro score:0.9237434730433176\n",
            "Batch 4\n",
            "jacc acc:0.894, f1 micro score:0.894 f1 macro score:0.8931343885472325\n",
            "Batch 5\n",
            "jacc acc:0.905, f1 micro score:0.905 f1 macro score:0.9045455413222352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {np.mean(accuracy)}, F1 Micro: {np.mean(f1_micro)}, F1 Macro: {np.mean(f1_macro)}')\n"
      ],
      "metadata": {
        "id": "Lx1xJI0Nz12g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fa425e-0aec-4daf-9c75-0d084c1cf035"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.9160093646112621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ED2Y7cr_DzWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}